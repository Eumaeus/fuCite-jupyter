{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aesop: Greek and Portuguese\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook takes a plain-text file containing the text of Aesop, *Fabulae*, 1–17, in the Greek edition of Helm (1872), and a new Portuguese translation by M.C. Dezotti (2020), and transforms it into a canonically-citable, CITE-compliant digital library serialized into [CEX format](http://cite-architecture.org/citedx/CEX-spec-3.0.1).\n",
    "\n",
    "**This is not a generic script!** The input file is clean and well-structured plain-text, but in an idiosyncratic format. Because it is well-structured, we can work with it. Because it is idiosyncratic, this is an exercise in *some techniques* for moving legacy data into CEX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring CITE libraries for almond kernel\n",
    "\n",
    "First, we'll make a bintray repository with CITE libraries available to your almond kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val myBT = coursierapi.MavenRepository.of(\"https://dl.bintray.com/neelsmith/maven\")\n",
    "interp.repositories() ++= Seq(myBT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we bring in specific libraries from the new repository using almond's `$ivy` magic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`edu.holycross.shot::ohco2:10.16.0`\n",
    "import $ivy.`edu.holycross.shot.cite::xcite:4.1.1`\n",
    "import $ivy.`edu.holycross.shot::scm:7.2.0`\n",
    "import $ivy.`edu.holycross.shot::dse:5.2.2`\n",
    "import $ivy.`edu.holycross.shot::citebinaryimage:3.1.1`\n",
    "import $ivy.`edu.holycross.shot::citeobj:7.3.4`\n",
    "import $ivy.`edu.holycross.shot::citerelations:2.5.2`\n",
    "import $ivy.`edu.holycross.shot::cex:6.3.3`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "From this point on, your notebook consists of completely generic Scala, with the CITE Libraries available to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Import some CITE libraries\n",
    "import edu.holycross.shot.cite._\n",
    "import edu.holycross.shot.ohco2._\n",
    "import edu.holycross.shot.scm._\n",
    "import edu.holycross.shot.citeobj._\n",
    "import edu.holycross.shot.citerelation._\n",
    "import edu.holycross.shot.dse._\n",
    "import edu.holycross.shot.citebinaryimage._\n",
    "import edu.holycross.shot.ohco2._\n",
    "\n",
    "import almond.display.UpdatableDisplay\n",
    "import almond.interpreter.api.DisplayData.ContentType\n",
    "import almond.interpreter.api.{DisplayData, OutputHandler}\n",
    "\n",
    "import java.io.File\n",
    "import java.io.PrintWriter\n",
    "\n",
    "import scala.io.Source\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function for saving a String to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveString(s:String, filePath:String = \"\", fileName:String = \"temp.txt\"):Unit = {\n",
    "\t\t val writer = new PrintWriter(new File(s\"${filePath}${fileName}\"))\n",
    "         writer.write(s)\n",
    "         writer.close()\n",
    "\t}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A function to pretty-print lists and OHCO2 corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showMe(v:Any):Unit = {\n",
    "  v match {\n",
    "    case _:StringHistogram => {\n",
    "        for ( h <- v.asInstanceOf[StringHistogram].histogram ) {\n",
    "            println(s\"${h.count}\\t${h.s}\")\n",
    "        }\n",
    "    }\n",
    "  \tcase _:Corpus => {\n",
    "  \t\tfor ( n <- v.asInstanceOf[Corpus].nodes) {\n",
    "  \t\t\tprintln(s\"${n.urn.passageComponent}\\t\\t${n.text}\")\n",
    "  \t\t}\t\n",
    "  \t}\n",
    "    case _:Vector[Any] => println(s\"\"\"\\n----\\n${v.asInstanceOf[Vector[Any]].mkString(\"\\n\")}\\n----\\n\"\"\")\n",
    "    case _:Iterable[Any] => println(s\"\"\"\\n----\\n${v.asInstanceOf[Iterable[Any]].mkString(\"\\n\")}\\n----\\n\"\"\")\n",
    "    case _ => println(s\"\\n-----\\n${v}\\n----\\n\")\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load a Template File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filePath = s\"aesop.txt\"\n",
    "val allLines: Vector[String] = {\n",
    "    scala.io.Source.fromFile(filePath).mkString.split(\"\\n\").toVector.filter( _.size > 0 )\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a custom Class that is String + Index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case class IndexedLine( text: String, index: Int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to separate heading-lines from the content-lines.\n",
    "\n",
    "Attach to each line of the text, an index-number (this will stay with the lines, and be useful later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val indexedLines: Vector[IndexedLine] = allLines.zipWithIndex.map ( l => {\n",
    "    IndexedLine( l._1, l._2 )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to pull out just the lines that are headings. We start with a Regular Expression pattern that (we happen to know) will match all of these lines: lines beginning with Arabic numerals are our headings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val pattern = \"^[0-9]\".r // note that .r after a String makes it into a RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we use that regular expression, `pattern` as a filter to get a Vector of just our heading-lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val headingLines: Vector[IndexedLine] = indexedLines.filter( l => {\n",
    "    pattern.findAllIn(l.text).size > 0\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Group Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to group our text by section. The procedure will be:\n",
    "\n",
    "- Identify the index number of one heading.\n",
    "- Identify the index number of the *next* heading.\n",
    "- Get all lines that fall between the two.\n",
    "- Attach them to the first heading.\n",
    "\n",
    "Scala's [`.sliding`](http://daily-scala.blogspot.com/2009/11/iteratorsliding.html) method is ideal for this. It will group all the headings into pairs.\n",
    "\n",
    "Below, `headingPairs` is a Vector of Vectors of IndexedLine objects. The inner Vector will have two IndexedLines, each one a heading. In the first pair will consist of the first heading and the second; the second pair will consist of the *second* heading (again) and the third."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val headingPairs: Vector[Vector[IndexedLine]] = headingLines.sliding(2,1).toVector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can map this Vector of pairs and get all the chapters except the last one. For the last one, we need a variant. \n",
    "\n",
    "> In other programming idioms, we would iterate through the pairs, with a check, each time, to see if we were on the last one, or beyond the last one. In Scala's Functional Programming Idiom, we \"do something to everything\", and know in advance that this will not include the last section, and treat that differently. This helps avoid \"off by one\" errors, among other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val mappedHeadings: Vector[( IndexedLine, Vector[IndexedLine])] = {\n",
    "    \n",
    "    // We use up all the pairs…\n",
    "    val allButLast: Vector[( IndexedLine, Vector[IndexedLine])] = headingPairs.map( p => {\n",
    "        val firstIndex: Int = p.head.index\n",
    "        val lastIndex: Int = p.last.index\n",
    "        val firstLine: IndexedLine = indexedLines(firstIndex)\n",
    "        val allLines: Vector[IndexedLine] = indexedLines.filter( il => {\n",
    "            ( il.index > firstIndex) & ( il.index < lastIndex )\n",
    "        })\n",
    "        ( firstLine, allLines )\n",
    "    })\n",
    "    \n",
    "    // We go get the last section, which we know was not included…\n",
    "    val lastSection: Vector[( IndexedLine, Vector[IndexedLine])] = {\n",
    "        val firstIndex: Int = headingPairs.last.last.index\n",
    "        val firstLine: IndexedLine = indexedLines(firstIndex)\n",
    "        val allLines: Vector[IndexedLine] = indexedLines.filter( il => {\n",
    "            ( il.index > firstIndex) \n",
    "        })\n",
    "        val tup = ( firstLine, allLines )\n",
    "        Vector[( IndexedLine, Vector[IndexedLine])](tup)\n",
    "    }\n",
    "    \n",
    "    // We concatenate the two Vectors…\n",
    "    allButLast ++ lastSection\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A Useful Function for Title Lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The title-line of this text consists of:\n",
    "\n",
    "- An Arabic number (1–17), followed by a period.\n",
    "- A Greek title\n",
    "- The Portuguese title\n",
    "\n",
    "In XML, *vel sim.*, all of these would be wrapped in some kind of markup. They are not, here, but we can still work with these three discrete sets of data, because the plain-text is clean and predictable.\n",
    "\n",
    "We *could* do this in-line, but it is easier to see, and test, if we pull it out into a defined Function.\n",
    "\n",
    "We grab the Heading-number (which we turn into a String, because it is merely a *label*), using a Regular Expression.\n",
    "\n",
    "To split the Greek title from the Portuguese title, we do the following:\n",
    "\n",
    "- Grab the chapter-label (some Arabic numerals) with a Regex\n",
    "- Remove the chapter-label (and following period '.') before further processing: this is the String `val` called `twoTitles`\n",
    "- Turn that into a Vector of `Char`.\n",
    "- Filter out everything except `[A-Z]` (we know that the Greek title is first, and the Portuguese title begins with an upper-case Latin letter).\n",
    "- The first element in the resulting list will be the start of the Portuguese title.\n",
    "- Using Scala's [`.indexOf`](https://www.geeksforgeeks.org/scala-string-indexof-method-with-example/) method, we get the index of the first occurrance of the first `Char` of the Portuguese title in the `twoTitles` String.\n",
    "- Using `.take` we grab the Greek title.\n",
    "- Using `.takeRight` and some arithmetic we grab the Portuguese title.\n",
    "\n",
    "The result will be a \"3ple\" of Strings: chapter-label, Greek title, Portugues title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTitle( testString: String ): (String, String, String) = {\n",
    "    \n",
    "    val chapterId: String = {\n",
    "        val rx = \"^[0-9]+\".r\n",
    "        val foundOption: Option[String] = rx.findFirstIn(testString)\n",
    "        foundOption.getOrElse(\"NO_ID\")\n",
    "        \n",
    "    }\n",
    "    \n",
    "    val twoTitles: String = testString.replaceAll(\"\"\"^[0-9]+\\.\"\"\", \"\").trim\n",
    "    \n",
    "    val charVec = twoTitles.toVector\n",
    "    val filteredVec = charVec.filter( c => {\n",
    "        val s = c.toString\n",
    "        val rpl = s.replaceAll(\"[A-Z]\", \"\")\n",
    "        rpl == \"\"\n",
    "    })\n",
    "    val firstChar: Char = filteredVec.head.toChar\n",
    "    val firstPorIndex: Int = charVec.indexOf(firstChar)\n",
    "    val greekTitle: String = twoTitles.take(firstPorIndex - 1)\n",
    "    val porTitle: String = twoTitles.takeRight( twoTitles.size - firstPorIndex )\n",
    "    \n",
    "    (chapterId, greekTitle, porTitle)\n",
    "}\n",
    "\n",
    "splitTitle(\"12. αβγδ ABCD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a CEX File!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make two CEX blocks, one for Greek and one for Portuguese. We happen to know that, for each section, there is a header-line, a Greek section (one line), and a Portuguese section (one line). \n",
    "\n",
    "**So this is not a generic script!** It only works with this file!\n",
    "\n",
    "First we define our URN-base:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val urnBase = CtsUrn(\"urn:cts:greekLit:tlg0096.tlg002:\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a CEX block for Greek first…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val greekBlock: Vector[String] = mappedHeadings.map( h => {\n",
    "    val heading: IndexedLine = h._1\n",
    "    val section: IndexedLine = h._2.head\n",
    "    val splitHeading = splitTitle(heading.text)\n",
    "    val sectionId = splitHeading._1\n",
    "    val sectionHeading = splitHeading._2\n",
    "    val versionUrn = urnBase.addVersion(\"First1K-grc1\")\n",
    "    Vector(\n",
    "        s\"${versionUrn}${sectionId}.head#${sectionHeading}\",\n",
    "        s\"${versionUrn}${sectionId}.text#${section.text}\"\n",
    "    )\n",
    "}).flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a CEX block for Portuguese…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val portBlock: Vector[String] = mappedHeadings.map( h => {\n",
    "    val heading: IndexedLine = h._1\n",
    "    val section: IndexedLine = h._2.last\n",
    "    val splitHeading = splitTitle(heading.text)\n",
    "    val sectionId = splitHeading._1\n",
    "    val sectionHeading = splitHeading._3\n",
    "    val versionUrn = urnBase.addVersion(\"mcdezotti\")\n",
    "    Vector(\n",
    "        s\"${versionUrn}${sectionId}.head#${sectionHeading}\",\n",
    "        s\"${versionUrn}${sectionId}.text#${section.text}\"\n",
    "    )\n",
    "}).flatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Assembly**\n",
    "\n",
    "We need to add the `#!ctsdata` header before each block, and of course the overall CEX header and CTS Catalog, which are convenientl saved in a separate template file.\n",
    "\n",
    "> Concatenating, appending, and prepending things to Vectors in Scala is flexible, but the syntax is hard to remember. [This site](https://alvinalexander.com/scala/how-to-append-prepend-items-vector-seq-in-scala) is the definitive reference.\n",
    "\n",
    "First, we load the CEX Header:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val filePath = s\"aesop_cex_header.txt\"\n",
    "val cexHeader: String = {\n",
    "    scala.io.Source.fromFile(filePath).mkString.split(\"\\n\").toVector.filter( _.size > 0 ).mkString(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now give our blocks their proper headers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val greekCex: String = {\n",
    "    ( \"#!ctsdata\" +: greekBlock ).mkString(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val portCex: String = {\n",
    "    ( \"#!ctsdata\" +: portBlock ).mkString(\"\\n\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the whole things together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val aesopCex: String = {\n",
    "    cexHeader + \"\\n\\n\" + greekCex + \"\\n\\n\" + portCex + \"\\n\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save it…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveString( aesopCex, \"\", \"aesop.cex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test It!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test the validity of our work by trying to load it into a [CiteLibrary](https://cite-architecture.github.io/cite-api-docs/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cexPath = \"aesop.cex\"\n",
    "val lib = CiteLibrary(scala.io.Source.fromFile(cexPath).mkString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If that worked (!??!), we can now try a little retrieval and analysis. \n",
    "\n",
    "A CITE Library has many possible components. The one we have just loaded is text-only, so let's get some parts of it convenient to hand.\n",
    "\n",
    "> A CiteLibrary possesses an `Option[TextRepository]`. So there may or may not be a TextRepository in any given CiteLibrary, the value of `lib.textRepository` may be either `Some[TextRepository]` or `None`. We can \"get\" the TR with `lib.textRepository.get`. If the value is actually `None`, this will throw an exception. But in that case, something failed, above, so there is no point doing elaborate checking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val tr: TextRepository = lib.textRepository.get // Go for it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A TextRepository **must** have both a `Catalog` and a `Corpus`. See [the API docs for the `OHCO2` library](https://cite-architecture.github.io/cite-api-docs/ohco2/api/edu/holycross/shot/ohco2/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val cat: Catalog = tr.catalog\n",
    "\n",
    "val corp: Corpus = tr.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, we will define some URNs, and use them to retrieve passage of text. This will take advantage of \n",
    "the `showMe()` Function defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Urn to Aesop's Fabulae\n",
    "val aesopUrn = CtsUrn(\"urn:cts:greekLit:tlg0096.tlg002:\")\n",
    "\n",
    "// Version ID for Greek\n",
    "val greekVers = \"First1K-grc1\"\n",
    "\n",
    "// Version ID for Portuguese\n",
    "val portVers = \"mcdezotti\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Fables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One fable, in Greek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val oneGreekCitation = aesopUrn.addVersion(greekVers).addPassage(\"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `~~` method to retrieve a passage, based on a URN, from a Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val oneGreekFable: Corpus = corp ~~ oneGreekCitation\n",
    "\n",
    "showMe(oneGreekFable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One fable, in Portuguese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val onePortCitation = aesopUrn.addVersion(portVers).addPassage(\"3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ~~ method to retrieve a passage, based on a URN, from a Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val onePortFable: Corpus = corp ~~ onePortCitation\n",
    "\n",
    "showMe(onePortFable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two fables, in Greek:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val twoGreekCitations = aesopUrn.addVersion(greekVers).addPassage(\"4-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the `~~` method to retrieve a passage, based on a URN, from a Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val twoGreekFables: Corpus = corp ~~ twoGreekCitations\n",
    "\n",
    "showMe(twoGreekFables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One fable, in Portuguese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val twoPortCitations = aesopUrn.addVersion(portVers).addPassage(\"4-5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the ~~ method to retrieve a passage, based on a URN, from a Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val twoPortFables: Corpus = corp ~~ twoPortCitations\n",
    "\n",
    "showMe(twoPortFables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Parts of Fables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above retrieve by canonical citation, that is, by Fable. The library we define separates the heading from the text of a fable, for more precise identification and retrieval, *if so desired*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fableFiveGreekHead: Corpus = {\n",
    "    corp ~~ aesopUrn.addVersion(greekVers).addPassage(\"5.head\")\n",
    "}\n",
    "\n",
    "showMe( fableFiveGreekHead )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fableFiveGreekText: Corpus = {\n",
    "    corp ~~ aesopUrn.addVersion(greekVers).addPassage(\"5.text\")\n",
    "}\n",
    "\n",
    "showMe( fableFiveGreekText )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve Multitext Fables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the [CITE Architecture](http://cite-architecture.org) has always been developed in the context of the [Homer Multitext](http://www.homermultitext.org), its *raison d’être* has been **identification and retrieval** of passages of texts, by **canonical citation**, across versions. We can capitalize on this here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fableFiveHeadAll: Corpus = {\n",
    "    corp ~~ aesopUrn.addPassage(\"5.head\")\n",
    "}\n",
    "\n",
    "showMe(fableFiveHeadAll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val fableFiveAll: Corpus = {\n",
    "    corp ~~ aesopUrn.addPassage(\"5\")\n",
    "}\n",
    "\n",
    "showMe(fableFiveAll)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information about using the [OCHO2 library’s built-in analytical tools](https://cite-architecture.github.io/cite-api-docs/ohco2/api/edu/holycross/shot/ohco2/index.html) see the [API documentation](https://cite-architecture.github.io/cite-api-docs/ohco2/api/edu/holycross/shot/ohco2/index.html). We can test our new library, though, with a quick linguistic analysis or two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do a quick search for an NGram, in Greek or Portuguese, or for the whole Corpus.\n",
    "\n",
    "We start by defining Corpora for analysis.\n",
    "\n",
    "**N.b.** The `val` named `corp`, the Corpus in our TextRepository, contains both Greek and Portuguese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val greekCorpus: Corpus = corp ~~ aesopUrn.addVersion(greekVers)\n",
    "\n",
    "val portCorpus: Corpus = corp ~~ aesopUrn.addVersion(portVers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We ask for repeating patterns of 3 words that occur more than 2 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val threeGramsGreek = greekCorpus.ngramHisto(3, 2)\n",
    "\n",
    "showMe( threeGramsGreek )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for Portuguese:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "val threeGramsPort = portCorpus.ngramHisto(3, 2)\n",
    "\n",
    "showMe( threeGramsPort )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do the same for both languages!:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val threeGramsAll = corp.ngramHisto(3, 2)\n",
    "\n",
    "showMe( threeGramsAll )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "scala"
  },
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.10"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
